{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install pytorch-geometric\n",
    "on mac: using pip wheel installation instructions, with python 3.9 and pytorch via conda (https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)\n",
    "\n",
    "loading data: \n",
    "ultimately: build on-disk dataset w/ pytorch \n",
    "atm: build dataset on the fly with synthetic dataset + data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# coords used in segmentation paper (polar is 2d, how?)\n",
    "#relative_polar = np.load('/Users/hannah.spitzer/projects/MELD/Benchmarking-Surface-DL/Segmentation_UGSCNN/GraphMethods/data/relative_coords_polar_3.npy')\n",
    "#relative_coord = np.load('/Users/hannah.spitzer/projects/MELD/Benchmarking-Surface-DL/Segmentation_UGSCNN/GraphMethods/data/relative_coords_3.npy')\n",
    "#edge_index_seg = np.load('/Users/hannah.spitzer/projects/MELD/Benchmarking-Surface-DL/Segmentation_UGSCNN/GraphMethods/data/edge_index_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting MELD_DATA_PATH to /Users/hannah.spitzer/projects/MELD/test_meld\n",
      "Setting BASE_PATH to /Users/hannah.spitzer/projects/MELD/Data\n",
      "Setting EXPERIMENT_PATH to /Users/hannah.spitzer/projects/MELD/experiments\n",
      "Setting FS_SUBJECTS_PATH to /Users/hannah.spitzer/projects/MELD/test_meld/output/fs_outputs\n",
      "No scripts_dir defined in /Users/hannah.spitzer/projects/MELD/meld_classifier/meld_classifier/meld_config.ini!\n",
      "WARNING: EXPERIMENT_PATH not found, setting to \"\", need to add it to paths.py\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import meld_graph\n",
    "import meld_graph.models\n",
    "import meld_graph.experiment\n",
    "import meld_graph.dataset\n",
    "importlib.reload(meld_graph)\n",
    "importlib.reload(meld_graph.models)\n",
    "importlib.reload(meld_graph.dataset)\n",
    "importlib.reload(meld_graph.experiment)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network_parameters = {\n",
    "    'network_type': 'MoNet',\n",
    "    'model_parameters': {\n",
    "        'layer_sizes': [30,30,30],\n",
    "        'dim': 2, # pseudo-coord dim\n",
    "        'kernel_size': 3, # number of gaussian kernels\n",
    "    },\n",
    "    'training_parameters': {\n",
    "        \"max_patience\": 400,\n",
    "        \"num_epochs\": 800,\n",
    "        'lr': 1e-2,\n",
    "        'loss': 'cross_entropy',\n",
    "        \"batch_size\": 1,\n",
    "        \"shuffle_each_epoch\": True,\n",
    "    },\n",
    "    # experiment name. If none, experiment is not saved TODO implement\n",
    "    'name': None,   #\"date\": datetime.datetime.now().strftime(\"%y-%m-%d\"),\n",
    "}\n",
    "\n",
    "data_parameters = {\n",
    "    'hdf5_file_root': \"{site_code}_{group}_featurematrix.hdf5\",\n",
    "    'site_codes': ['H4'],\n",
    "    'scanners': ['15T', '3T'],\n",
    "    'dataset': 'MELD_dataset_V1.csv',\n",
    "    'group': 'both',\n",
    "    \"features_to_exclude\": [],\n",
    "    \"subject_features_to_exclude\": [],\n",
    "    \"features\": ['.on_lh.curv.mgh',\n",
    "        '.on_lh.gm_FLAIR_0.25.mgh',\n",
    "        '.on_lh.gm_FLAIR_0.5.mgh',\n",
    "        '.on_lh.gm_FLAIR_0.75.mgh',\n",
    "        '.on_lh.gm_FLAIR_0.mgh',\n",
    "        '.on_lh.pial.K_filtered.sm20.mgh',\n",
    "        '.on_lh.sulc.mgh',\n",
    "        '.on_lh.thickness.mgh',\n",
    "        '.on_lh.w-g.pct.mgh',\n",
    "        '.on_lh.wm_FLAIR_0.5.mgh',\n",
    "        '.on_lh.wm_FLAIR_1.mgh'],\n",
    "    \"features_to_replace_with_0\": [], # specify this if manually specifying features\n",
    "    \"number_of_folds\": 10,\n",
    "    \"fold_n\": 0,\n",
    "    \"preprocessing_parameters\": {\n",
    "        \"scaling\": \"scaling_params_GDL.json\"\n",
    "    },\n",
    "    \"icosphere_parameters\": {\n",
    "        \"distance_type\": \"exact\", #\"exact\",  # exact or pseudo\n",
    "    },\n",
    "    \"combine_hemis\": None,  # None, stack, TODO: combine with graph\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:meld_graph.dataset:Loading and preprocessing data\n",
      "INFO:meld_graph.dataset:Combine hemis None\n",
      "INFO:meld_graph.data_preprocessing:Scale data using file /Users/hannah.spitzer/projects/MELD/Data/scaling_params_GDL.json\n",
      "INFO:meld_graph.data_preprocessing:Scale data using file /Users/hannah.spitzer/projects/MELD/Data/scaling_params_GDL.json\n"
     ]
    }
   ],
   "source": [
    "exp = meld_graph.experiment.Experiment(network_parameters, data_parameters, save=False)\n",
    "_ = exp.get_train_val_test_ids()\n",
    "exp.data_parameters['train_ids'] = exp.data_parameters['train_ids'][:2]\n",
    "exp.data_parameters['val_ids'] = exp.data_parameters['val_ids'][:2]\n",
    "ds = meld_graph.dataset.GraphDataset.from_experiment(exp, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:meld_graph.icospheres:Using coord type exact\n"
     ]
    }
   ],
   "source": [
    "exp.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = exp.model.icospheres.get_edges(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds[0].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([163842, 11])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool from 7 to 6\n",
    "import torch\n",
    "hex_5 = torch.LongTensor(np.load('/Users/hannah.spitzer/projects/MELD/Benchmarking-Surface-DL/Segmentation_UGSCNN/GraphMethods/data/hexagons_6.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0, 18097,  ..., 19649, 23977, 23976],\n",
       "        [    1,     1, 25168,  ..., 22409, 20448, 20449],\n",
       "        [    2,     2, 21233,  ..., 22785, 28681, 28680],\n",
       "        ...,\n",
       "        [40959,  3969, 15744,  ..., 10241, 40960, 40961],\n",
       "        [40960, 40961, 40959,  ..., 40947, 22031,  5576],\n",
       "        [40961, 15745,  3969,  ..., 40960,  5576, 22032]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours = list(exp.model.icospheres.icospheres[6]['neighbours'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh6 = np.concatenate([np.array(neighbours[:12])[:,0:1], np.array(neighbours[:12])], axis=1)\n",
    "neigh6 = np.concatenate([neigh6, np.array(neighbours[12:])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40962, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([163842, 11])\n",
      "(40962, 6)\n",
      "torch.Size([40962, 6, 11])\n",
      "torch.Size([40962, 11])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "class HexPool(nn.Module):\n",
    "    def __init__(self, icoshperes, level):\n",
    "        super(HexPool, self).__init__()\n",
    "        self.neigh = icoshperes.get_neighbours(level=level)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x[:len(self.neigh)][self.neigh]\n",
    "        x = torch.max(x, dim=1)[0]\n",
    "        return x\n",
    "\n",
    "class HexUnpool(nn.Module):\n",
    "    def __init__(self, icoshperes, level, device):\n",
    "        super(HexUnpool, self).__init__()\n",
    "        self.upsample = icoshperes.get_upsample(level=level)\n",
    "        self.neigh = icoshperes.get_neighbours(level=level)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        limit = int(x.shape[0])\n",
    "        new_x = torch.zeros(self.neigh.shape[0],x.shape[1]).to(self.device)\n",
    "        new_x[:limit] = x\n",
    "        new_x[limit:] = torch.mean(x[self.upsample],dim=1)\n",
    "        return new_x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 282])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co-spit1/.conda/envs/meld_graph/lib/python3.9/site-packages/torch/cuda/__init__.py:143: UserWarning: \n",
      "NVIDIA A100-SXM-80GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA A100-SXM-80GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mMeldCohort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhdf5_file_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{site_code}_{group}_featurematrix_combat.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      Class to define cohort-level parameters such as subject ids, mesh\n",
      "\u001b[0;31mFile:\u001b[0m           ~/projects/MELD/meld_classifier/meld_classifier/meld_cohort.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "from meld_classifier.meld_cohort import MeldCohort\n",
    "\n",
    "cohort = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_combat6.hdf5', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e336a35d61f60f865ab0873d0d0cc82dcfe64a783bf2c2b281a1493d54951c12"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
