{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting MELD_DATA_PATH to /rds/project/kw350/rds-kw350-meld/meld_data/Data\n",
      "Setting BASE_PATH to /rds/project/kw350/rds-kw350-meld/meld_data/Data\n",
      "Setting EXPERIMENT_PATH to /rds/project/kw350/rds-kw350-meld/experiments/co-ripa1/\n",
      "Setting FS_SUBJECTS_PATH to \n",
      "Setting EXPERIMENT_PATH to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.data\n",
    "\n",
    "import meld_graph\n",
    "import meld_graph.training\n",
    "import meld_graph.models\n",
    "import meld_graph.experiment\n",
    "import meld_graph.dataset\n",
    "from meld_graph.paths import load_config\n",
    "from meld_graph.paths import EXPERIMENT_PATH\n",
    "from meld_graph.dataset import GraphDataset, Oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving parameter files to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00\n",
      "Initialised Experiment 23-05-19_MATH_test_histology_head\n"
     ]
    }
   ],
   "source": [
    "# create experiment\n",
    "config_file = '/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/scripts/config_files/base_config_test.py'\n",
    "config = load_config(config_file)\n",
    "exp = meld_graph.experiment.Experiment(config.network_parameters, config.data_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'meld_graph.training' from '/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(meld_graph.dataset)\n",
    "importlib.reload(meld_graph.data_preprocessing)\n",
    "importlib.reload(meld_graph.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "# create the trainer the model\n",
    "trainer = meld_graph.training.Trainer(exp)\n",
    "trainer.experiment.load_model()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "trainer.experiment.model.to(device)\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting train val test split\n",
      "total number of subjects: 45\n",
      "total number of subjects after restricting to subjects from MELD_dataset_V6.csv: 45\n",
      "total number of subjects: 950\n",
      "total number of subjects after restricting to subjects from MELD_dataset_V6.csv: 942\n",
      "total number after filtering by scanner ['3T', '15T'], features, lesional_only True: 911\n",
      "full_feature_list: ['.combat.on_lh.curv.sm5.mgh', '.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.combat.on_lh.pial.K_filtered.sm20.mgh', '.combat.on_lh.sulc.sm5.mgh', '.combat.on_lh.thickness.sm10.mgh', '.combat.on_lh.w-g.pct.sm10.mgh', '.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.combat.on_lh.wm_FLAIR_1.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.curv.sm5.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.pial.K_filtered.sm20.mgh', '.inter_z.asym.intra_z.combat.on_lh.sulc.sm5.mgh', '.inter_z.asym.intra_z.combat.on_lh.thickness.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.w-g.pct.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.wm_FLAIR_1.sm10.mgh', '.inter_z.intra_z.combat.on_lh.curv.sm5.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.inter_z.intra_z.combat.on_lh.pial.K_filtered.sm20.mgh', '.inter_z.intra_z.combat.on_lh.sulc.sm5.mgh', '.inter_z.intra_z.combat.on_lh.thickness.sm10.mgh', '.inter_z.intra_z.combat.on_lh.w-g.pct.sm10.mgh', '.inter_z.intra_z.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.inter_z.intra_z.combat.on_lh.wm_FLAIR_1.sm10.mgh']\n",
      "total number after filtering by scanner ['15T', '3T'], features, lesional_only True: 45\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/numeric.py:1211: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = asanyarray(a)\n",
      "Saving parameter files to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00\n",
      "Loading and preprocessing train data\n",
      "Z-scoring data for MELD_H10_3T_C_0027\n",
      "Z-scoring data for MELD_H10_3T_C_0026\n",
      "Z-scoring data for MELD_H10_3T_FCD_0011\n",
      "Z-scoring data for MELD_H10_3T_FCD_0001\n",
      "Z-scoring data for MELD_H10_3T_FCD_0010\n",
      "Z-scoring data for MELD_H10_3T_C_0003\n",
      "Z-scoring data for MELD_H10_3T_C_0032\n",
      "Z-scoring data for MELD_H10_3T_FCD_0015\n",
      "Z-scoring data for MELD_H10_3T_FCD_0004\n",
      "Z-scoring data for MELD_H10_3T_C_0023\n",
      "Z-scoring data for MELD_H10_3T_C_0016\n",
      "Z-scoring data for MELD_H10_3T_FCD_0005\n",
      "Z-scoring data for MELD_H10_3T_C_0008\n",
      "Z-scoring data for MELD_H10_3T_C_0004\n",
      "Z-scoring data for MELD_H10_3T_C_0010\n",
      "Z-scoring data for MELD_H10_3T_FCD_0006\n",
      "Z-scoring data for MELD_H10_3T_C_0024\n",
      "Z-scoring data for MELD_H10_3T_C_0020\n",
      "Z-scoring data for MELD_H10_3T_FCD_0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphDataset(38)\n"
     ]
    }
   ],
   "source": [
    "train_dset = GraphDataset.from_experiment(trainer.experiment, mode='train')\n",
    "print(train_dset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing val data\n",
      "Z-scoring data for MELD_H10_3T_C_0007\n",
      "Z-scoring data for MELD_H10_3T_C_0002\n",
      "Z-scoring data for MELD_H10_3T_FCD_0003\n",
      "Z-scoring data for MELD_H10_3T_C_0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphDataset(8)\n"
     ]
    }
   ],
   "source": [
    "val_dset = GraphDataset.from_experiment(trainer.experiment, mode='val')\n",
    "print(val_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler=None\n",
    "shuffle = trainer.params['shuffle_each_epoch']\n",
    "batch_size = trainer.params['batch_size']\n",
    "optimiser = torch.optim.SGD(trainer.experiment.model.parameters(), **trainer.params['optimiser_parameters'])\n",
    "optimiser = optimiser\n",
    "\n",
    "train_data_loader = torch_geometric.loader.DataLoader(\n",
    "             train_dset, sampler=sampler, \n",
    "             shuffle=shuffle,\n",
    "             batch_size= batch_size,\n",
    "             num_workers=0, persistent_workers=False, prefetch_factor=2\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:449: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  elif metric == 'histo_precision':\n"
     ]
    }
   ],
   "source": [
    "cur_scores = trainer.train_epoch(train_data_loader, optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cross_entropy': 0.6554559230804443,\n",
       " 'dice': 0.9847615841776133,\n",
       " 'distance_regression': 0.4588208019733429,\n",
       " 'lesion_classification': 0.745412266254425,\n",
       " 'histology_classification': 1.4951695680618287,\n",
       " 'ds6_cross_entropy': 0.042364323139190675,\n",
       " 'ds5_cross_entropy': 0.059493355453014374,\n",
       " 'ds4_cross_entropy': 0.1940973311662674,\n",
       " 'ds3_cross_entropy': 0.4693894386291504,\n",
       " 'ds6_dice': 0.061441260296851395,\n",
       " 'ds5_dice': 0.12169606997631491,\n",
       " 'ds4_dice': 0.24401496760547162,\n",
       " 'ds3_dice': 0.4835611624643207,\n",
       " 'ds6_distance_regression': 0.025491341203451156,\n",
       " 'ds5_distance_regression': 0.039177677035331725,\n",
       " 'ds4_distance_regression': 0.13558775037527085,\n",
       " 'ds3_distance_regression': 0.27978743612766266,\n",
       " 'ds6_lesion_classification': nan,\n",
       " 'ds5_lesion_classification': nan,\n",
       " 'ds4_lesion_classification': nan,\n",
       " 'ds3_lesion_classification': nan,\n",
       " 'ds6_histology_classification': nan,\n",
       " 'ds5_histology_classification': nan,\n",
       " 'ds4_histology_classification': nan,\n",
       " 'ds3_histology_classification': nan,\n",
       " 'loss': 6.495722257019952,\n",
       " 'dice_lesion': 0.005952427885495127,\n",
       " 'dice_nonlesion': 0.8190030932426453,\n",
       " 'precision': 0.0032136751421574035,\n",
       " 'recall': 0.2709435626102293,\n",
       " 'tp': 6145,\n",
       " 'fp': 1905996,\n",
       " 'fn': 16535,\n",
       " 'auroc': 0.5309265673160553,\n",
       " 'cl_precision': 0.21052631578947367,\n",
       " 'cl_recall': 1.0,\n",
       " 'histo_precision': 0.02857142857142857}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model already exists. Specify force=True to force reloading and initialisation\n",
      "Creating model\n",
      "Getting train val test split\n",
      "total number of subjects: 45\n",
      "total number of subjects after restricting to subjects from MELD_dataset_V6.csv: 45\n",
      "total number of subjects: 950\n",
      "total number of subjects after restricting to subjects from MELD_dataset_V6.csv: 942\n",
      "total number after filtering by scanner ['3T', '15T'], features, lesional_only True: 911\n",
      "full_feature_list: ['.combat.on_lh.curv.sm5.mgh', '.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.combat.on_lh.pial.K_filtered.sm20.mgh', '.combat.on_lh.sulc.sm5.mgh', '.combat.on_lh.thickness.sm10.mgh', '.combat.on_lh.w-g.pct.sm10.mgh', '.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.combat.on_lh.wm_FLAIR_1.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.curv.sm5.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.pial.K_filtered.sm20.mgh', '.inter_z.asym.intra_z.combat.on_lh.sulc.sm5.mgh', '.inter_z.asym.intra_z.combat.on_lh.thickness.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.w-g.pct.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.inter_z.asym.intra_z.combat.on_lh.wm_FLAIR_1.sm10.mgh', '.inter_z.intra_z.combat.on_lh.curv.sm5.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.25.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.5.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.75.sm10.mgh', '.inter_z.intra_z.combat.on_lh.gm_FLAIR_0.sm10.mgh', '.inter_z.intra_z.combat.on_lh.pial.K_filtered.sm20.mgh', '.inter_z.intra_z.combat.on_lh.sulc.sm5.mgh', '.inter_z.intra_z.combat.on_lh.thickness.sm10.mgh', '.inter_z.intra_z.combat.on_lh.w-g.pct.sm10.mgh', '.inter_z.intra_z.combat.on_lh.wm_FLAIR_0.5.sm10.mgh', '.inter_z.intra_z.combat.on_lh.wm_FLAIR_1.sm10.mgh']\n",
      "total number after filtering by scanner ['15T', '3T'], features, lesional_only True: 45\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/numeric.py:1211: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  a = asanyarray(a)\n",
      "Saving parameter files to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00\n",
      "Loading and preprocessing train data\n",
      "Z-scoring data for MELD_H10_3T_C_0027\n",
      "Z-scoring data for MELD_H10_3T_C_0026\n",
      "Z-scoring data for MELD_H10_3T_FCD_0011\n",
      "Z-scoring data for MELD_H10_3T_FCD_0001\n",
      "Z-scoring data for MELD_H10_3T_FCD_0010\n",
      "Z-scoring data for MELD_H10_3T_C_0003\n",
      "Z-scoring data for MELD_H10_3T_C_0032\n",
      "Z-scoring data for MELD_H10_3T_FCD_0015\n",
      "Z-scoring data for MELD_H10_3T_FCD_0004\n",
      "Z-scoring data for MELD_H10_3T_C_0023\n",
      "Z-scoring data for MELD_H10_3T_C_0016\n",
      "Z-scoring data for MELD_H10_3T_FCD_0005\n",
      "Z-scoring data for MELD_H10_3T_C_0008\n",
      "Z-scoring data for MELD_H10_3T_C_0004\n",
      "Z-scoring data for MELD_H10_3T_C_0010\n",
      "Z-scoring data for MELD_H10_3T_FCD_0006\n",
      "Z-scoring data for MELD_H10_3T_C_0024\n",
      "Z-scoring data for MELD_H10_3T_C_0020\n",
      "Z-scoring data for MELD_H10_3T_FCD_0007\n",
      "Loading and preprocessing val data\n",
      "Z-scoring data for MELD_H10_3T_C_0007\n",
      "Z-scoring data for MELD_H10_3T_C_0002\n",
      "Z-scoring data for MELD_H10_3T_FCD_0003\n",
      "Z-scoring data for MELD_H10_3T_C_0030\n",
      "Stopping metric set to loss \n",
      "using max_epochs 100 for lr decay\n",
      "Epoch 0 :: learning rate 0.0001\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:446: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  metrics['cl_precision'] = (cl_tp/(cl_tp+cl_fp)).item()\n",
      "/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:455: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  metrics[f'histo_{i}_accuracy'] = (histo_tp[i]/(histo_tp[i]+histo_fp[i])).item()\n",
      "Epoch 0 :: time 106.26799201965332\n",
      "Epoch 0 :: memory usage 6751.83203125MB\n",
      "Epoch 0 :: Train cross_entropy 1.166, dice 0.980, distance_regression 0.413, lesion_classification 0.692, histology_classification 1.398, loss 6.617, dice_lesion 0.014, dice_nonlesion 0.000, precision 0.007, recall 1.000, tp 28038.000, fp 3904170.000, fn 0.000, auroc 0.514, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy nan, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.619, histo_4_accuracy 0.619\n",
      "Epoch 0 :: Val   cross_entropy 1.091, dice 0.986, distance_regression 0.475, lesion_classification 0.677, histology_classification 1.586, loss 6.879, dice_lesion 0.009, dice_nonlesion 0.000, precision 0.005, recall 1.000, tp 6108.000, fp 1304628.000, fn 0.000, auroc 0.504, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy nan, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.875, histo_4_accuracy 0.875\n",
      "Saved new best model to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00/best_model.pt\n",
      "Epoch 1 :: learning rate 9.909954834128343e-05\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/co-ripa1/.conda/envs/meld_graph/lib/python3.9/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:446: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  metrics['cl_precision'] = (cl_tp/(cl_tp+cl_fp)).item()\n",
      "/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:455: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  metrics[f'histo_{i}_accuracy'] = (histo_tp[i]/(histo_tp[i]+histo_fp[i])).item()\n",
      "Epoch 1 :: time 98.48824119567871\n",
      "Epoch 1 :: memory usage 6752.08203125MB\n",
      "Epoch 1 :: Train cross_entropy 1.150, dice 0.979, distance_regression 0.420, lesion_classification 0.690, histology_classification 1.328, loss 6.467, dice_lesion 0.015, dice_nonlesion 0.000, precision 0.007, recall 1.000, tp 28947.000, fp 3903261.000, fn 0.000, auroc 0.526, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy 0.000, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.684, histo_4_accuracy 0.684\n",
      "Epoch 1 :: Val   cross_entropy 1.041, dice 0.986, distance_regression 0.474, lesion_classification 0.676, histology_classification 1.583, loss 6.718, dice_lesion 0.009, dice_nonlesion 0.000, precision 0.005, recall 1.000, tp 6108.000, fp 1304628.000, fn 0.000, auroc 0.479, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy nan, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.875, histo_4_accuracy 0.875\n",
      "Saved new best model to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00/best_model.pt\n",
      "Epoch 2 :: learning rate 9.819818665965754e-05\n",
      "Epoch 2 :: time 100.84083890914917\n",
      "Epoch 2 :: memory usage 7403.953125MB\n",
      "Epoch 2 :: Train cross_entropy 1.054, dice 0.973, distance_regression 0.402, lesion_classification 0.694, histology_classification 1.262, loss 6.130, dice_lesion 0.018, dice_nonlesion 0.000, precision 0.009, recall 1.000, tp 34986.000, fp 3897222.000, fn 0.000, auroc 0.530, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy nan, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.632, histo_4_accuracy 0.632\n",
      "Epoch 2 :: Val   cross_entropy 0.989, dice 0.985, distance_regression 0.474, lesion_classification 0.676, histology_classification 1.578, loss 6.526, dice_lesion 0.009, dice_nonlesion 0.000, precision 0.005, recall 1.000, tp 6108.000, fp 1304628.000, fn 0.000, auroc 0.450, cl_precision nan, cl_recall 0.000, histo_0_precision 0.000, histo_0_accuracy nan, histo_1_precision 0.000, histo_1_accuracy nan, histo_2_precision 0.000, histo_2_accuracy nan, histo_3_precision 0.000, histo_3_accuracy nan, histo_4_precision 0.875, histo_4_accuracy 0.875\n",
      "Saved new best model to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-ripa1/23-05-19_MATH_test_histology_head/fold_00/best_model.pt\n",
      "Epoch 3 :: learning rate 9.729590473501306e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/notebooks/develop_classification_histology_head.ipynb Cell 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blogin-e-16.hpc.cam.ac.uk/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/notebooks/develop_classification_histology_head.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(wandb_logging\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:686\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, wandb_logging)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m :: learning rate \u001b[39m\u001b[39m{\u001b[39;00mscheduler\u001b[39m.\u001b[39mget_last_lr()[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    685\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 686\u001b[0m cur_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(train_data_loader, optimiser)\n\u001b[1;32m    687\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m :: time \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    688\u001b[0m scheduler\u001b[39m.\u001b[39mstep()  \u001b[39m# update lr\u001b[39;00m\n",
      "File \u001b[0;32m/rds/user/co-ripa1/hpc-work/scripts/meld_classifier_GDL/meld_graph/training.py:518\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, data_loader, optimiser)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[39m# calculate overall loss\u001b[39;00m\n\u001b[1;32m    517\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(losses\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m--> 518\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    519\u001b[0m optimiser\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    520\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mloss_dictionary\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys()):\n",
      "File \u001b[0;32m~/.conda/envs/meld_graph/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/meld_graph/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    155\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    156\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(wandb_logging=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meld_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
