{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meld_graph.experiment\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib_surface_plotting as msp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import nibabel as nb\n",
    "from meld_classifier.paths import BASE_PATH\n",
    "from meld_classifier.meld_cohort import MeldCohort,MeldSubject\n",
    "def load_prediction(subject,hdf5,dset='prediction'):\n",
    "    results={}\n",
    "    with h5py.File(hdf5, \"r\") as f:\n",
    "        for hemi in ['lh','rh']:\n",
    "            results[hemi] = f[subject][hemi][dset][:]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_spiral_fold/s_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_combat_6.hdf5',\n",
    "               dataset='MELD_dataset_V6.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.arange(0,9)\n",
    "\n",
    "save_dirs = {\n",
    "    'spiral': [os.path.join(model_path,f'fold_0{fold}', 'results') for fold in folds] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vert = len(cohort.cortex_label)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(save_dirs['spiral'][0], 'predictions.hdf5'), \"r\") as f:\n",
    "    subjects = list(f.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curves(subject_dictionary,roc_dictionary):\n",
    "    \"\"\"calculate performance at multiple thresholds\"\"\"\n",
    "    roc_curves_thresholds=np.linspace(0,1,21)\n",
    "    for t_i,threshold in enumerate(roc_curves_thresholds):\n",
    "        predicted = subject_dictionary['result']>= threshold\n",
    "        # if we want tpr vs fpr curve too\n",
    "        # tp,fp,fn, tn = tp_fp_fn_tn(predicted, subject_dictionary['input_labels'])\n",
    "        #store sensitivity and sensitivity_plus for each patient (has a label)\n",
    "        if subject_dictionary['input_labels'].sum()>0:\n",
    "            roc_dictionary['sensitivity'][t_i] += np.logical_and(predicted, subject_dictionary['input_labels']).any()\n",
    "            roc_dictionary['sensitivity_plus'][t_i] += np.logical_and(predicted, subject_dictionary['borderzone']).any()\n",
    "        #store specificity for controls (no label)\n",
    "        else:\n",
    "            roc_dictionary['specificity'][t_i] += ~predicted.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "roc_dictionary={'sensitivity':np.zeros(21),\n",
    "'sensitivity_plus':np.zeros(21),\n",
    "'specificity':np.zeros(21)}\n",
    "for si,subj in enumerate(subjects):\n",
    "    if si%100==0:\n",
    "        print(si)\n",
    "    s = MeldSubject(subj,cohort=cohort)\n",
    "    labels_hemis = {}\n",
    "    dists={}\n",
    "    subject_results = np.zeros(n_vert)\n",
    "    labels = np.zeros(n_vert)\n",
    "    for hemi in ['lh','rh']:\n",
    "        dists[hemi], labels_hemis[hemi] = s.load_feature_lesion_data(\n",
    "                    features=['.on_lh.boundary_zone.mgh'], hemi=hemi, features_to_ignore=[]\n",
    "                )\n",
    "        if np.sum(dists[hemi])==0:\n",
    "            dists[hemi] +=200\n",
    "    labels = np.hstack([labels_hemis['lh'][cohort.cortex_mask],labels_hemis['rh'][cohort.cortex_mask]])\n",
    "    borderzones = np.vstack([dists['lh'][cohort.cortex_mask,:],dists['rh'][cohort.cortex_mask,:]]).ravel()<20\n",
    "    for fold in folds:\n",
    "        save_dir = save_dirs['spiral'][fold]\n",
    "        pred_file = os.path.join(save_dir, 'predictions.hdf5')\n",
    "        result_hemis = load_prediction(subj,pred_file, dset='prediction')\n",
    "        subject_results += np.hstack([result_hemis['lh']/10,result_hemis['rh']/10])\n",
    "    subject_dictionary={'input_labels':labels,'borderzone':borderzones,'result':subject_results}\n",
    "    roc_curves(subject_dictionary,roc_dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_threshold(b):\n",
    "    thresholds=np.linspace(0,1,21)\n",
    "    youden = b['sensitivity_plus']/max(b['sensitivity_plus'])+b['specificity']/max(b['specificity'])\n",
    "    optimal_thresh =thresholds[np.max(np.where(youden==np.max(youden)))]\n",
    "    print(optimal_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"model path doesn't contain the fold bit. this is then looped over\"\"\"\n",
    "        #load models\n",
    "        self.models=[]\n",
    "        for fold in np.arange(10):\n",
    "            fold_path = os.path.join(model_path,f'fold_0{fold}')\n",
    "            exp = meld_graph.experiment.Experiment.from_folder(fold_path)\n",
    "            exp.load_model(\n",
    "                        checkpoint_path=os.path.join(fold_path, \"best_model.pt\"),\n",
    "                        force=True,\n",
    "                    )\n",
    "            self.models.append(exp.model)\n",
    "        self.network_parameters = exp.network_parameters\n",
    "\n",
    "    def predict(self,data):\n",
    "        \"\"\"function to predict and average\"\"\"\n",
    "        predictions=[]\n",
    "        distance_maps=[]\n",
    "        for model in self.models:\n",
    "            estimates = model(data)\n",
    "            predictions.append(torch.exp(estimates['log_softmax'])[:,1].numpy)\n",
    "            #get distance map if exist in loss, otherwise return array of NaN\n",
    "            if 'distance_regression' in self.network_parameters['training_parameters']['loss_dictionary'].keys():\n",
    "                distance_map = estimates['non_lesion_logits'][:,0]\n",
    "            else: \n",
    "                distance_map = torch.full((len(prediction),1), torch.nan)[:,0]\n",
    "            distance_maps = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_00/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_01/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_02/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_03/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_04/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_05/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_06/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_07/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_08/best_model.pt\n",
      "Initialised Experiment 23-01-13_QXFB_kernel_GMM_fold/s_2\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-01-13_QXFB_kernel_GMM_fold/s_2/fold_09/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "models=[]\n",
    "for fold in np.arange(10):\n",
    "    fold_path = os.path.join(model_path,f'fold_0{fold}')\n",
    "    exp = meld_graph.experiment.Experiment.from_folder(fold_path)\n",
    "    exp.load_model(\n",
    "                checkpoint_path=os.path.join(fold_path, \"best_model.pt\"),\n",
    "                force=True,\n",
    "            )\n",
    "    models.append(exp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/kw350/software/gdl/meld_classifier_GDL/notebooks/ensemble.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blogin.hpc.cam.ac.uk/home/kw350/software/gdl/meld_classifier_GDL/notebooks/ensemble.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m models[\u001b[39m0\u001b[39m](data\u001b[39m.\u001b[39mx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meld_graph",
   "language": "python",
   "name": "meld_graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
