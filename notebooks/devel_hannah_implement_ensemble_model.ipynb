{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f207787b",
   "metadata": {},
   "source": [
    "# MELD\n",
    "Ensembling:\n",
    "* use create_ensemble.py to create ensemble model. TODO: use Ensemble module + save (first part of notebook)\n",
    "* put load_ensemble_model in Experiment class, use this to load model when “all” in path, or checkpoint path “ensemble_model.pt”. \n",
    "* use cross_val_aucs /  evaluate_single_model.py to create predictions\n",
    "\n",
    "Scripts to adapt:\n",
    "- ensemble.sh -> rename to evaluate_ensemble / evaluate_model? -> -> renamed to ensemble_tmp.sh can be replaced with scripts \n",
    "- ensemble_bs.sh -> use single fold predictions and have subsequenct script that calculates this -> so should probably stay as is\n",
    "- adapt cross_vall_aucs to use full fold?\n",
    "\n",
    "Scripts I’m not sure about:\n",
    "* comparing_exps?\n",
    "* run_evaluation_models_valsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c18ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting EXPERIMENT_PATH to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1\n",
      "Setting MELD_DATA_PATH to /home/co-spit1/meld_data\n",
      "Setting BASE_PATH to /home/co-spit1/meld_data\n",
      "Setting EXPERIMENT_PATH to /home/co-spit1/meld_experiments/co-spit1\n",
      "Setting FS_SUBJECTS_PATH to /home/co-spit1/meld_data/output/fs_outputs\n"
     ]
    }
   ],
   "source": [
    "import meld_graph.experiment\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib_surface_plotting as msp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import nibabel as nb\n",
    "from meld_classifier.paths import BASE_PATH\n",
    "from meld_classifier.meld_cohort import MeldCohort,MeldSubject\n",
    "\n",
    "from meld_graph.experiment import Experiment\n",
    "from meld_graph.dataset import GraphDataset\n",
    "import torch\n",
    "import torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9898142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = '/rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-02-09_MYCZ_baseline/s_2/'\n",
    "\n",
    "cohort = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_combat_6.hdf5',\n",
    "               dataset='MELD_dataset_V6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f51c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.arange(5)\n",
    "\n",
    "exp_dirs = [os.path.join(model_path1,f'fold_0{fold}') for fold in folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de5c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n"
     ]
    }
   ],
   "source": [
    "exps = [Experiment.from_folder(exp_dir) for exp_dir in exp_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812fa654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Creating model\n",
      "Creating model\n",
      "Creating model\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "for exp in exps:\n",
    "    exp.load_model(os.path.join(exp.experiment_path, exp.experiment_name, f'fold_0{exp.fold}', 'best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe39bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing test data\n",
      "Z-scoring data for MELD_H17_3T_FCD_0035\n",
      "Z-scoring data for MELD_H21_15T_FCD_0039\n",
      "Z-scoring data for MELD_H2_3T_C_0024\n",
      "Z-scoring data for MELD_H19_3T_C_027\n",
      "Z-scoring data for MELD_H15_3T_C_0028\n",
      "Z-scoring data for MELD_H23_15T_FCD_0007\n",
      "Z-scoring data for MELD_H2_3T_C_0015\n",
      "Z-scoring data for MELD_H10_3T_C_0010\n",
      "Z-scoring data for MELD_H19_3T_C_022\n",
      "Z-scoring data for MELD_H14_3T_FCD_0019\n"
     ]
    }
   ],
   "source": [
    "train_ids, val_ids, test_ids = exp.get_train_val_test_ids()\n",
    "dataset = GraphDataset(val_ids[:10], cohort, exp.data_parameters, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008e4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch_geometric.loader.DataLoader(\n",
    "        dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c9c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9c50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble models\n",
    "    \"\"\"\n",
    "    def __init__(self, models):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        estimates = [model(x) for model in self.models]\n",
    "        ensembled_estimates = {}\n",
    "        for key in ['log_softmax', 'hemi_log_softmax', 'non_lesion_logits']:\n",
    "            if key not in estimates[0].keys():\n",
    "                continue\n",
    "            if 'log_softmax' in key:\n",
    "                # there are the logged outputs -> before mean, need to do exp \n",
    "                vals = torch.stack([torch.exp(est[key]) for est in estimates], dim=2)\n",
    "                mean_val = torch.log(torch.mean(vals, dim=2))\n",
    "            else:\n",
    "                mean_val = torch.mean(torch.stack([est[key] for est in estimates], dim=2), dim=2)\n",
    "            ensembled_estimates[key] = mean_val\n",
    "        return ensembled_estimates\n",
    "\n",
    "ensemble = Ensemble([exp.model for exp in exps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75f870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "for i, data in enumerate(data_loader):\n",
    "    estimates = ensemble(data.x)\n",
    "    \n",
    "    # single folds for comparison\n",
    "    #estimates_folds = [exp.model(data.x) for exp in exps]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283f2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7415, -0.6470],\n",
      "        [-0.6825, -0.7039],\n",
      "        [-0.6615, -0.7258],\n",
      "        ...,\n",
      "        [-0.6694, -0.7174],\n",
      "        [-0.6647, -0.7224],\n",
      "        [-0.6719, -0.7149]], grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimates_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(estimates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m estimates_exp \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mexp(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mestimates_folds\u001b[49m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(estimates_exp, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimates_folds' is not defined"
     ]
    }
   ],
   "source": [
    "print(estimates['log_softmax'])\n",
    "\n",
    "estimates_exp = [torch.exp(f['log_softmax']) for f in estimates_folds]\n",
    "print(torch.log(torch.mean(torch.stack(estimates_exp, dim=2), dim=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a91f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0771],\n",
      "        [0.1123],\n",
      "        [0.6275],\n",
      "        ...,\n",
      "        [0.2871],\n",
      "        [0.3094],\n",
      "        [0.3253]], grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.0008],\n",
      "        [-0.0036],\n",
      "        [ 0.0858],\n",
      "        ...,\n",
      "        [ 0.5935],\n",
      "        [ 0.3564],\n",
      "        [ 0.5201]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(estimates['non_lesion_logits'])\n",
    "print(estimates_folds[1]['non_lesion_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b0d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try saving \n",
    "fname = 'ensemble_model.pt'\n",
    "torch.save(ensemble.state_dict(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65b500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model - function of experiment\n",
    "import copy\n",
    "def load_ensemble_model(self, checkpoint_path=None, force=False):\n",
    "    if self.model is not None and not force:\n",
    "        self.log.info(\"Model already exists. Specify force=True to force reloading and initialisation\")\n",
    "    # create model without checkpoint\n",
    "    self.load_model()\n",
    "    self.log.info('Creating ensemble model')\n",
    "    models = [copy.deepcopy(self.model) for _ in range(5)]  # TODO this assumes that we are always ensembling 5 models\n",
    "    ensemble_model = Ensemble(models)\n",
    "    self.model = ensemble_model\n",
    "    # load weights from checkpoint    \n",
    "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
    "        # checkpoint contains both model architecture + weights\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.log.info(f\"Loading ensemble model weights from checkpoint {checkpoint_path}\")\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=False)\n",
    "        self.model.eval()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8de4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Creating model\n",
      "Creating ensemble model\n",
      "Loading ensemble model weights from checkpoint ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_folder(exp_dirs[0])\n",
    "load_ensemble_model(exp, checkpoint_path='ensemble_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f9fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models.0.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0221,  0.0101,  0.0660,  ..., -0.0428, -0.1122,  0.1257],\n",
      "        [ 0.0143, -0.1232, -0.1224,  ...,  0.0849, -0.1058, -0.1137],\n",
      "        [-0.0957, -0.0019, -0.0765,  ..., -0.1396,  0.0537, -0.0704],\n",
      "        ...,\n",
      "        [ 0.0984,  0.1123, -0.0475,  ..., -0.1067, -0.0964, -0.0556],\n",
      "        [ 0.0423, -0.0554,  0.0813,  ..., -0.0362,  0.0256, -0.0608],\n",
      "        [ 0.0188, -0.0310,  0.0262,  ..., -0.0885,  0.1057,  0.1313]],\n",
      "       requires_grad=True)\n",
      "models.1.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0652,  0.1312,  0.0249,  ..., -0.0338, -0.0195,  0.1057],\n",
      "        [-0.0112,  0.0018, -0.1078,  ..., -0.1149,  0.1087,  0.0882],\n",
      "        [ 0.0339, -0.0840,  0.0183,  ..., -0.0995,  0.1258,  0.1251],\n",
      "        ...,\n",
      "        [-0.0856,  0.0723,  0.1273,  ...,  0.1211, -0.0441,  0.1299],\n",
      "        [ 0.0139,  0.1479, -0.1146,  ..., -0.0530, -0.0415,  0.1139],\n",
      "        [ 0.0209,  0.0913, -0.0453,  ...,  0.0547, -0.0367,  0.0165]],\n",
      "       requires_grad=True)\n",
      "models.2.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0993,  0.0227, -0.1440,  ..., -0.0420,  0.1196, -0.0439],\n",
      "        [ 0.0902, -0.0311,  0.0904,  ...,  0.0756, -0.1158,  0.1261],\n",
      "        [ 0.1180,  0.0300,  0.1114,  ...,  0.0022, -0.0100,  0.0554],\n",
      "        ...,\n",
      "        [ 0.0689,  0.0868,  0.1324,  ...,  0.1508, -0.1150,  0.0677],\n",
      "        [-0.1387, -0.1215, -0.1283,  ..., -0.1478, -0.0971,  0.1081],\n",
      "        [-0.1046, -0.1068, -0.1307,  ...,  0.1019,  0.1088,  0.0921]],\n",
      "       requires_grad=True)\n",
      "models.3.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0982,  0.0542, -0.0868,  ..., -0.1130,  0.0240,  0.0348],\n",
      "        [-0.0829, -0.0365, -0.0688,  ..., -0.0291, -0.0995, -0.0341],\n",
      "        [-0.0367,  0.0940,  0.0283,  ...,  0.0996, -0.1469,  0.1111],\n",
      "        ...,\n",
      "        [-0.0892,  0.0010, -0.0123,  ...,  0.0517,  0.1139,  0.0578],\n",
      "        [-0.1470, -0.0303,  0.1107,  ...,  0.0984, -0.0834, -0.0924],\n",
      "        [-0.1005, -0.0935, -0.0296,  ..., -0.1233, -0.0382, -0.0707]],\n",
      "       requires_grad=True)\n",
      "models.4.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0121, -0.0063, -0.0504,  ..., -0.0793,  0.1149, -0.0787],\n",
      "        [-0.1116,  0.1377,  0.1351,  ...,  0.0595,  0.0032, -0.1420],\n",
      "        [ 0.0701,  0.0061, -0.0942,  ...,  0.0912,  0.0643, -0.0966],\n",
      "        ...,\n",
      "        [ 0.1324, -0.0180, -0.0188,  ..., -0.0731,  0.0500,  0.0987],\n",
      "        [ 0.0881, -0.0931,  0.0566,  ...,  0.0642,  0.0521, -0.1301],\n",
      "        [-0.0688,  0.0581, -0.1271,  ..., -0.1259,  0.0425,  0.0996]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check that have different weights in different models\n",
    "for name, param in exp.model.named_parameters():\n",
    "    if 'encoder_conv_layers.0.0.layer.weight' in name:\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fbb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "for i, data in enumerate(data_loader):\n",
    "    estimates2 = exp.model(data.x)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05668376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(estimates['log_softmax'] == estimates2['log_softmax']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c785acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
