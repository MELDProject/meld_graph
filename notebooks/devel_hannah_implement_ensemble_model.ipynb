{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f207787b",
   "metadata": {},
   "source": [
    "# MELD\n",
    "Ensembling:\n",
    "* use create_ensemble.py to create ensemble model. TODO: use Ensemble module + save (first part of notebook)\n",
    "* put load_ensemble_model in Experiment class, use this to load model when “all” in path, or checkpoint path “ensemble_model.pt”. \n",
    "* use cross_val_aucs /  evaluate_single_model.py to create predictions\n",
    "\n",
    "Scripts to adapt:\n",
    "- ensemble.sh -> rename to evaluate_ensemble / evaluate_model? -> -> renamed to ensemble_tmp.sh can be replaced with scripts \n",
    "- ensemble_bs.sh -> use single fold predictions and have subsequenct script that calculates this -> so should probably stay as is\n",
    "- adapt cross_vall_aucs to use full fold?\n",
    "\n",
    "Scripts I’m not sure about:\n",
    "* comparing_exps?\n",
    "* run_evaluation_models_valsdata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c18ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting EXPERIMENT_PATH to /rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1\n",
      "Setting MELD_DATA_PATH to /home/co-spit1/meld_data\n",
      "Setting BASE_PATH to /home/co-spit1/meld_data\n",
      "Setting EXPERIMENT_PATH to /home/co-spit1/meld_experiments/co-spit1\n",
      "Setting FS_SUBJECTS_PATH to /home/co-spit1/meld_data/output/fs_outputs\n"
     ]
    }
   ],
   "source": [
    "import meld_graph.experiment\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib_surface_plotting as msp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import nibabel as nb\n",
    "from meld_classifier.paths import BASE_PATH\n",
    "from meld_classifier.meld_cohort import MeldCohort,MeldSubject\n",
    "\n",
    "from meld_graph.experiment import Experiment\n",
    "from meld_graph.dataset import GraphDataset\n",
    "import torch\n",
    "import torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9898142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path1 = '/rds/project/kw350/rds-kw350-meld/experiments_graph/kw350/23-02-09_MYCZ_baseline/s_2/'\n",
    "\n",
    "cohort = MeldCohort(hdf5_file_root='{site_code}_{group}_featurematrix_combat_6.hdf5',\n",
    "               dataset='MELD_dataset_V6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f51c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = np.arange(5)\n",
    "\n",
    "exp_dirs = [os.path.join(model_path1,f'fold_0{fold}') for fold in folds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de5c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n"
     ]
    }
   ],
   "source": [
    "exps = [Experiment.from_folder(exp_dir) for exp_dir in exp_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812fa654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model\n",
      "Creating model\n",
      "Creating model\n",
      "Creating model\n",
      "Creating model\n"
     ]
    }
   ],
   "source": [
    "for exp in exps:\n",
    "    exp.load_model(os.path.join(exp.experiment_path, exp.experiment_name, f'fold_0{exp.fold}', 'best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe39bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing test data\n",
      "Z-scoring data for MELD_H17_3T_FCD_0035\n",
      "Z-scoring data for MELD_H21_15T_FCD_0039\n",
      "Z-scoring data for MELD_H2_3T_C_0024\n",
      "Z-scoring data for MELD_H19_3T_C_027\n",
      "Z-scoring data for MELD_H15_3T_C_0028\n",
      "Z-scoring data for MELD_H23_15T_FCD_0007\n",
      "Z-scoring data for MELD_H2_3T_C_0015\n",
      "Z-scoring data for MELD_H10_3T_C_0010\n",
      "Z-scoring data for MELD_H19_3T_C_022\n",
      "Z-scoring data for MELD_H14_3T_FCD_0019\n"
     ]
    }
   ],
   "source": [
    "train_ids, val_ids, test_ids = exp.get_train_val_test_ids()\n",
    "dataset = GraphDataset(val_ids[:10], cohort, exp.data_parameters, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008e4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch_geometric.loader.DataLoader(\n",
    "        dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c9c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9c50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble models\n",
    "    \"\"\"\n",
    "    def __init__(self, models):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        estimates = [model(x) for model in self.models]\n",
    "        ensembled_estimates = {}\n",
    "        for key in ['log_softmax', 'hemi_log_softmax', 'non_lesion_logits']:\n",
    "            if key not in estimates[0].keys():\n",
    "                continue\n",
    "            if 'log_softmax' in key:\n",
    "                # there are the logged outputs -> before mean, need to do exp \n",
    "                vals = torch.stack([torch.exp(est[key]) for est in estimates], dim=2)\n",
    "                mean_val = torch.log(torch.mean(vals, dim=2))\n",
    "            else:\n",
    "                mean_val = torch.mean(torch.stack([est[key] for est in estimates], dim=2), dim=2)\n",
    "            ensembled_estimates[key] = mean_val\n",
    "        return ensembled_estimates\n",
    "\n",
    "ensemble = Ensemble([exp.model for exp in exps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75f870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "for i, data in enumerate(data_loader):\n",
    "    estimates = ensemble(data.x)\n",
    "    \n",
    "    # single folds for comparison\n",
    "    #estimates_folds = [exp.model(data.x) for exp in exps]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283f2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7415, -0.6470],\n",
      "        [-0.6825, -0.7039],\n",
      "        [-0.6615, -0.7258],\n",
      "        ...,\n",
      "        [-0.6694, -0.7174],\n",
      "        [-0.6647, -0.7224],\n",
      "        [-0.6719, -0.7149]], grad_fn=<LogBackward0>)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimates_folds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(estimates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m estimates_exp \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mexp(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mestimates_folds\u001b[49m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(estimates_exp, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimates_folds' is not defined"
     ]
    }
   ],
   "source": [
    "print(estimates['log_softmax'])\n",
    "\n",
    "estimates_exp = [torch.exp(f['log_softmax']) for f in estimates_folds]\n",
    "print(torch.log(torch.mean(torch.stack(estimates_exp, dim=2), dim=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23a91f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0771],\n",
      "        [0.1123],\n",
      "        [0.6275],\n",
      "        ...,\n",
      "        [0.2871],\n",
      "        [0.3094],\n",
      "        [0.3253]], grad_fn=<MeanBackward1>)\n",
      "tensor([[-0.0008],\n",
      "        [-0.0036],\n",
      "        [ 0.0858],\n",
      "        ...,\n",
      "        [ 0.5935],\n",
      "        [ 0.3564],\n",
      "        [ 0.5201]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(estimates['non_lesion_logits'])\n",
    "print(estimates_folds[1]['non_lesion_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b0d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try saving \n",
    "fname = 'ensemble_model.pt'\n",
    "torch.save(ensemble.state_dict(), fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65b500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model - function of experiment\n",
    "import copy\n",
    "def load_ensemble_model(self, checkpoint_path=None, force=False):\n",
    "    if self.model is not None and not force:\n",
    "        self.log.info(\"Model already exists. Specify force=True to force reloading and initialisation\")\n",
    "    # create model without checkpoint\n",
    "    self.load_model()\n",
    "    self.log.info('Creating ensemble model')\n",
    "    models = [copy.deepcopy(self.model) for _ in range(5)]  # TODO this assumes that we are always ensembling 5 models\n",
    "    ensemble_model = Ensemble(models)\n",
    "    self.model = ensemble_model\n",
    "    # load weights from checkpoint    \n",
    "    if checkpoint_path is not None and os.path.isfile(checkpoint_path):\n",
    "        # checkpoint contains both model architecture + weights\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.log.info(f\"Loading ensemble model weights from checkpoint {checkpoint_path}\")\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=False)\n",
    "        self.model.eval()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8de4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-02-09_MYCZ_baseline/s_2\n",
      "Creating model\n",
      "Creating ensemble model\n",
      "Loading ensemble model weights from checkpoint ensemble_model.pt\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_folder(exp_dirs[0])\n",
    "load_ensemble_model(exp, checkpoint_path='ensemble_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f9fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models.0.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0221,  0.0101,  0.0660,  ..., -0.0428, -0.1122,  0.1257],\n",
      "        [ 0.0143, -0.1232, -0.1224,  ...,  0.0849, -0.1058, -0.1137],\n",
      "        [-0.0957, -0.0019, -0.0765,  ..., -0.1396,  0.0537, -0.0704],\n",
      "        ...,\n",
      "        [ 0.0984,  0.1123, -0.0475,  ..., -0.1067, -0.0964, -0.0556],\n",
      "        [ 0.0423, -0.0554,  0.0813,  ..., -0.0362,  0.0256, -0.0608],\n",
      "        [ 0.0188, -0.0310,  0.0262,  ..., -0.0885,  0.1057,  0.1313]],\n",
      "       requires_grad=True)\n",
      "models.1.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0652,  0.1312,  0.0249,  ..., -0.0338, -0.0195,  0.1057],\n",
      "        [-0.0112,  0.0018, -0.1078,  ..., -0.1149,  0.1087,  0.0882],\n",
      "        [ 0.0339, -0.0840,  0.0183,  ..., -0.0995,  0.1258,  0.1251],\n",
      "        ...,\n",
      "        [-0.0856,  0.0723,  0.1273,  ...,  0.1211, -0.0441,  0.1299],\n",
      "        [ 0.0139,  0.1479, -0.1146,  ..., -0.0530, -0.0415,  0.1139],\n",
      "        [ 0.0209,  0.0913, -0.0453,  ...,  0.0547, -0.0367,  0.0165]],\n",
      "       requires_grad=True)\n",
      "models.2.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0993,  0.0227, -0.1440,  ..., -0.0420,  0.1196, -0.0439],\n",
      "        [ 0.0902, -0.0311,  0.0904,  ...,  0.0756, -0.1158,  0.1261],\n",
      "        [ 0.1180,  0.0300,  0.1114,  ...,  0.0022, -0.0100,  0.0554],\n",
      "        ...,\n",
      "        [ 0.0689,  0.0868,  0.1324,  ...,  0.1508, -0.1150,  0.0677],\n",
      "        [-0.1387, -0.1215, -0.1283,  ..., -0.1478, -0.0971,  0.1081],\n",
      "        [-0.1046, -0.1068, -0.1307,  ...,  0.1019,  0.1088,  0.0921]],\n",
      "       requires_grad=True)\n",
      "models.3.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0982,  0.0542, -0.0868,  ..., -0.1130,  0.0240,  0.0348],\n",
      "        [-0.0829, -0.0365, -0.0688,  ..., -0.0291, -0.0995, -0.0341],\n",
      "        [-0.0367,  0.0940,  0.0283,  ...,  0.0996, -0.1469,  0.1111],\n",
      "        ...,\n",
      "        [-0.0892,  0.0010, -0.0123,  ...,  0.0517,  0.1139,  0.0578],\n",
      "        [-0.1470, -0.0303,  0.1107,  ...,  0.0984, -0.0834, -0.0924],\n",
      "        [-0.1005, -0.0935, -0.0296,  ..., -0.1233, -0.0382, -0.0707]],\n",
      "       requires_grad=True)\n",
      "models.4.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0121, -0.0063, -0.0504,  ..., -0.0793,  0.1149, -0.0787],\n",
      "        [-0.1116,  0.1377,  0.1351,  ...,  0.0595,  0.0032, -0.1420],\n",
      "        [ 0.0701,  0.0061, -0.0942,  ...,  0.0912,  0.0643, -0.0966],\n",
      "        ...,\n",
      "        [ 0.1324, -0.0180, -0.0188,  ..., -0.0731,  0.0500,  0.0987],\n",
      "        [ 0.0881, -0.0931,  0.0566,  ...,  0.0642,  0.0521, -0.1301],\n",
      "        [-0.0688,  0.0581, -0.1271,  ..., -0.1259,  0.0425,  0.0996]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check that have different weights in different models\n",
    "for name, param in exp.model.named_parameters():\n",
    "    if 'encoder_conv_layers.0.0.layer.weight' in name:\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fbb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "for i, data in enumerate(data_loader):\n",
    "    estimates2 = exp.model(data.x)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05668376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(estimates['log_softmax'] == estimates2['log_softmax']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f4bac",
   "metadata": {},
   "source": [
    "# test ensemble weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0bc39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = '/rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_all/results/predictions.hdf5'\n",
    "\n",
    "pred_old = ['/rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_{:02d}/results/predictions.hdf5'.format(i) for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b60cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-03-01_WRZI_classification_distance/s_0\n",
      "Creating model\n",
      "Creating ensemble model\n",
      "Loading ensemble model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_all/ensemble_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "models.0.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0135,  0.0678, -0.1863,  ..., -0.0700,  0.0781,  0.1409],\n",
      "        [ 0.0575,  0.0788,  0.1911,  ..., -0.0310,  0.1473, -0.1491],\n",
      "        [-0.0663,  0.0588,  0.0205,  ...,  0.0970,  0.0491, -0.1521],\n",
      "        ...,\n",
      "        [ 0.0257,  0.1267, -0.1367,  ...,  0.0021, -0.1042,  0.0584],\n",
      "        [-0.0381, -0.1887, -0.0417,  ...,  0.0391, -0.0844,  0.1380],\n",
      "        [-0.0173,  0.0530,  0.0020,  ...,  0.0463,  0.0730, -0.0912]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "models.1.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 1.7754e-02, -5.4374e-02, -1.9490e-01,  ..., -4.8245e-02,\n",
      "         -1.2372e-01, -1.3056e-01],\n",
      "        [-9.8838e-02,  3.7685e-02, -1.0103e-01,  ...,  4.2706e-03,\n",
      "         -9.9560e-02,  1.8284e-01],\n",
      "        [-1.6257e-01, -9.5077e-02,  4.9327e-02,  ..., -1.2854e-01,\n",
      "         -1.5518e-01,  2.4872e-02],\n",
      "        ...,\n",
      "        [ 1.4830e-01, -9.6151e-02,  2.1876e-01,  ...,  5.6988e-02,\n",
      "         -1.2685e-01,  9.8054e-02],\n",
      "        [-1.1729e-01, -2.7780e-01,  9.3867e-02,  ..., -1.6494e-01,\n",
      "         -1.5701e-01, -9.7613e-02],\n",
      "        [-1.5188e-01,  4.8490e-02,  1.2421e-02,  ..., -7.7111e-02,\n",
      "         -9.4015e-02, -4.3886e-05]], device='cuda:0', requires_grad=True)\n",
      "models.2.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 1.1640e-01,  1.7308e-01,  7.9184e-02,  ...,  1.0347e-02,\n",
      "         -8.9990e-02,  1.1169e-02],\n",
      "        [ 6.0996e-02, -1.5193e-01, -2.2906e-02,  ...,  9.6772e-02,\n",
      "          2.7335e-02,  6.4524e-02],\n",
      "        [ 5.3237e-02, -1.5989e-01, -1.2535e-02,  ..., -7.2330e-03,\n",
      "          1.8676e-04, -6.4904e-02],\n",
      "        ...,\n",
      "        [ 1.2609e-02,  9.4639e-02, -2.0779e-01,  ..., -1.7479e-01,\n",
      "         -4.4366e-02,  1.1233e-02],\n",
      "        [ 1.9952e-02, -6.4342e-02, -5.1590e-02,  ...,  6.4930e-02,\n",
      "         -1.0378e-01, -7.1205e-03],\n",
      "        [ 8.1933e-02, -7.3051e-02, -1.6260e-01,  ..., -4.1550e-02,\n",
      "         -1.5886e-01, -6.7386e-02]], device='cuda:0', requires_grad=True)\n",
      "models.3.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0354, -0.2662, -0.0637,  ..., -0.1421,  0.0979, -0.1330],\n",
      "        [ 0.0023, -0.0740,  0.1792,  ...,  0.1179,  0.1646,  0.0780],\n",
      "        [ 0.1265, -0.1736,  0.0450,  ...,  0.0445,  0.0873, -0.1966],\n",
      "        ...,\n",
      "        [ 0.0869, -0.1143,  0.1659,  ..., -0.0578,  0.1283, -0.1771],\n",
      "        [ 0.0905, -0.1852,  0.0358,  ...,  0.1154,  0.0912, -0.0183],\n",
      "        [ 0.1349, -0.0515, -0.0272,  ..., -0.1233, -0.0696,  0.0981]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "models.4.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0964, -0.0303, -0.2568,  ..., -0.0100,  0.0073,  0.1811],\n",
      "        [-0.2472, -0.2779, -0.2335,  ..., -0.0712,  0.0808,  0.0855],\n",
      "        [-0.1395, -0.1223,  0.0364,  ..., -0.0673, -0.0291, -0.1043],\n",
      "        ...,\n",
      "        [ 0.0704, -0.2699, -0.0856,  ...,  0.0664, -0.0428,  0.0066],\n",
      "        [-0.1507,  0.0445, -0.0636,  ..., -0.0841,  0.0146,  0.0942],\n",
      "        [ 0.0214,  0.1315, -0.1017,  ..., -0.0373,  0.0062,  0.1481]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_folder(os.path.dirname(os.path.dirname(pred_new)))\n",
    "exp.load_model(checkpoint_path=os.path.join(os.path.dirname(os.path.dirname(pred_new)), 'ensemble_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6526249e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models.0.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0135,  0.0678, -0.1863,  ..., -0.0700,  0.0781,  0.1409],\n",
      "        [ 0.0575,  0.0788,  0.1911,  ..., -0.0310,  0.1473, -0.1491],\n",
      "        [-0.0663,  0.0588,  0.0205,  ...,  0.0970,  0.0491, -0.1521],\n",
      "        ...,\n",
      "        [ 0.0257,  0.1267, -0.1367,  ...,  0.0021, -0.1042,  0.0584],\n",
      "        [-0.0381, -0.1887, -0.0417,  ...,  0.0391, -0.0844,  0.1380],\n",
      "        [-0.0173,  0.0530,  0.0020,  ...,  0.0463,  0.0730, -0.0912]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "models.1.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 1.7754e-02, -5.4374e-02, -1.9490e-01,  ..., -4.8245e-02,\n",
      "         -1.2372e-01, -1.3056e-01],\n",
      "        [-9.8838e-02,  3.7685e-02, -1.0103e-01,  ...,  4.2706e-03,\n",
      "         -9.9560e-02,  1.8284e-01],\n",
      "        [-1.6257e-01, -9.5077e-02,  4.9327e-02,  ..., -1.2854e-01,\n",
      "         -1.5518e-01,  2.4872e-02],\n",
      "        ...,\n",
      "        [ 1.4830e-01, -9.6151e-02,  2.1876e-01,  ...,  5.6988e-02,\n",
      "         -1.2685e-01,  9.8054e-02],\n",
      "        [-1.1729e-01, -2.7780e-01,  9.3867e-02,  ..., -1.6494e-01,\n",
      "         -1.5701e-01, -9.7613e-02],\n",
      "        [-1.5188e-01,  4.8490e-02,  1.2421e-02,  ..., -7.7111e-02,\n",
      "         -9.4015e-02, -4.3886e-05]], device='cuda:0', requires_grad=True)\n",
      "models.2.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 1.1640e-01,  1.7308e-01,  7.9184e-02,  ...,  1.0347e-02,\n",
      "         -8.9990e-02,  1.1169e-02],\n",
      "        [ 6.0996e-02, -1.5193e-01, -2.2906e-02,  ...,  9.6772e-02,\n",
      "          2.7335e-02,  6.4524e-02],\n",
      "        [ 5.3237e-02, -1.5989e-01, -1.2535e-02,  ..., -7.2330e-03,\n",
      "          1.8676e-04, -6.4904e-02],\n",
      "        ...,\n",
      "        [ 1.2609e-02,  9.4639e-02, -2.0779e-01,  ..., -1.7479e-01,\n",
      "         -4.4366e-02,  1.1233e-02],\n",
      "        [ 1.9952e-02, -6.4342e-02, -5.1590e-02,  ...,  6.4930e-02,\n",
      "         -1.0378e-01, -7.1205e-03],\n",
      "        [ 8.1933e-02, -7.3051e-02, -1.6260e-01,  ..., -4.1550e-02,\n",
      "         -1.5886e-01, -6.7386e-02]], device='cuda:0', requires_grad=True)\n",
      "models.3.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0354, -0.2662, -0.0637,  ..., -0.1421,  0.0979, -0.1330],\n",
      "        [ 0.0023, -0.0740,  0.1792,  ...,  0.1179,  0.1646,  0.0780],\n",
      "        [ 0.1265, -0.1736,  0.0450,  ...,  0.0445,  0.0873, -0.1966],\n",
      "        ...,\n",
      "        [ 0.0869, -0.1143,  0.1659,  ..., -0.0578,  0.1283, -0.1771],\n",
      "        [ 0.0905, -0.1852,  0.0358,  ...,  0.1154,  0.0912, -0.0183],\n",
      "        [ 0.1349, -0.0515, -0.0272,  ..., -0.1233, -0.0696,  0.0981]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "models.4.encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[-0.0964, -0.0303, -0.2568,  ..., -0.0100,  0.0073,  0.1811],\n",
      "        [-0.2472, -0.2779, -0.2335,  ..., -0.0712,  0.0808,  0.0855],\n",
      "        [-0.1395, -0.1223,  0.0364,  ..., -0.0673, -0.0291, -0.1043],\n",
      "        ...,\n",
      "        [ 0.0704, -0.2699, -0.0856,  ...,  0.0664, -0.0428,  0.0066],\n",
      "        [-0.1507,  0.0445, -0.0636,  ..., -0.0841,  0.0146,  0.0942],\n",
      "        [ 0.0214,  0.1315, -0.1017,  ..., -0.0373,  0.0062,  0.1481]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check that have different weights in different models\n",
    "for name, param in exp.model.named_parameters():\n",
    "    if 'encoder_conv_layers.0.0.layer.weight' in name:\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fc5275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_00/results/predictions.hdf5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_old[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a641319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialised Experiment 23-03-01_WRZI_classification_distance/s_0\n",
      "Creating model\n",
      "Loading model weights from checkpoint /rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_00/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_folder(os.path.dirname(os.path.dirname(pred_old[0])))\n",
    "exp.load_model(checkpoint_path=os.path.join(os.path.dirname(os.path.dirname(pred_old[0])), 'best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e926a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_conv_layers.0.0.layer.weight Parameter containing:\n",
      "tensor([[ 0.0135,  0.0678, -0.1863,  ..., -0.0700,  0.0781,  0.1409],\n",
      "        [ 0.0575,  0.0788,  0.1911,  ..., -0.0310,  0.1473, -0.1491],\n",
      "        [-0.0663,  0.0588,  0.0205,  ...,  0.0970,  0.0491, -0.1521],\n",
      "        ...,\n",
      "        [ 0.0257,  0.1267, -0.1367,  ...,  0.0021, -0.1042,  0.0584],\n",
      "        [-0.0381, -0.1887, -0.0417,  ...,  0.0391, -0.0844,  0.1380],\n",
      "        [-0.0173,  0.0530,  0.0020,  ...,  0.0463,  0.0730, -0.0912]],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# check that have different weights in different models\n",
    "for name, param in exp.model.named_parameters():\n",
    "    if 'encoder_conv_layers.0.0.layer.weight' in name:\n",
    "        print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae1756",
   "metadata": {},
   "source": [
    "# test ensemble == old ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5674ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction(subject, hdf5, dset=\"prediction\"):\n",
    "    \"\"\"load network predictions\"\"\"\n",
    "    results = {}\n",
    "    with h5py.File(hdf5, \"r\") as f:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            results[hemi] = f[subject][hemi][dset][:]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56960cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = '/rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_all/results/predictions.hdf5'\n",
    "\n",
    "pred_old = ['/rds/project/kw350/rds-kw350-meld/experiments_graph/co-spit1/23-03-01_WRZI_classification_distance/s_0/fold_{:02d}/results/predictions.hdf5'.format(i) for i in range(5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99b83396",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in h5py.File(pred_new, 'r').keys():\n",
    "    cur_pred_new = load_prediction(subj, pred_new)\n",
    "    cur_dist_new = load_prediction(subj, pred_new, 'distance_map')\n",
    "    \n",
    "    cur_pred_old = [load_prediction(subj, pred_old[i]) for i in range(len(pred_old))]\n",
    "    cur_dist_old = [load_prediction(subj, pred_old[i], 'distance_map') for i in range(len(pred_old))]\n",
    "    cur_pred_old = {key: np.mean([el[key] for el in cur_pred_old], axis=0) for key in ['lh', 'rh']}\n",
    "    cur_dist_old = {key: np.mean([el[key] for el in cur_dist_old], axis=0) for key in ['lh', 'rh']}\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc68a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lh': array([0.9781834 , 0.9768862 , 0.98737544, ..., 0.98798925, 0.98062724,\n",
       "        0.9801443 ], dtype=float32),\n",
       " 'rh': array([0.9708452 , 0.97811127, 0.98222953, ..., 0.9299162 , 0.9237982 ,\n",
       "        0.924417  ], dtype=float32)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dist_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "052d4df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lh': array([0.9782877 , 0.9769354 , 0.9873139 , ..., 0.98792744, 0.9807186 ,\n",
       "        0.9801723 ], dtype=float32),\n",
       " 'rh': array([0.970753  , 0.9781333 , 0.9822982 , ..., 0.9299806 , 0.92383635,\n",
       "        0.92440826], dtype=float32)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_dist_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3876db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lh': array([0.00063497, 0.00057976, 0.00055508, ..., 0.00059896, 0.00059915,\n",
       "        0.00059624], dtype=float32),\n",
       " 'rh': array([0.00059764, 0.00055042, 0.00053709, ..., 0.0012079 , 0.00108543,\n",
       "        0.00112827], dtype=float32)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_pred_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cf35d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lh': array([0.00063511, 0.0005796 , 0.00055496, ..., 0.00059833, 0.00059884,\n",
       "        0.00059585], dtype=float32),\n",
       " 'rh': array([0.00059716, 0.0005501 , 0.00053674, ..., 0.00120773, 0.00108533,\n",
       "        0.00112824], dtype=float32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70dcac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
